{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":285,"status":"ok","timestamp":1684886160988,"user":{"displayName":"Layfort","userId":"05574237463148173604"},"user_tz":-540},"id":"wznm91xISAl2"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"bLznNKUfvdi_"},"source":["\n","# 1) Implement tiling and commnucation\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1684886165137,"user":{"displayName":"Layfort","userId":"05574237463148173604"},"user_tz":-540},"id":"NbTCzw7-SNlQ"},"outputs":[],"source":["def tmul(tileA, tileB, t):    \n","    \n","    # Check if the input dimension <= tile_size    \n","    assert tileA.size(0) <= t\n","    assert tileA.size(1) <= t\n","    assert tileB.size(1) <= t\n","    \n","    return tileA @ tileB"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"v2uB1Ai1v2Fp"},"source":["# 2) Implement custom network"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":285,"status":"ok","timestamp":1684886543719,"user":{"displayName":"Layfort","userId":"05574237463148173604"},"user_tz":-540},"id":"sZPAfZ9bSVDZ"},"outputs":[],"source":["def conv2d(inputs, weights, padding, tile_size, bias=None, sim=None):\n","    o_chn, i_chn, kernel_size, _ = weights.size()\n","    bs, i_chn, res, _ = inputs.size()\n","    \n","    def weight_lowering():\n","        lowered_weights = weights.reshape(o_chn, i_chn*kernel_size*kernel_size)\n","        return lowered_weights\n","\n","    def inputs_lowering():\n","        # padding\n","        pad, _ = padding\n","        inputs_padded = torch.zeros(bs, i_chn, res+ pad * 2, res + pad * 2).type(torch.int8)\n","        inputs_padded[..., pad:res+pad, pad:res+pad] = inputs\n","\n","        lowered_inputs = torch.zeros(kernel_size*kernel_size, i_chn, bs, res*res).type(torch.int8)\n","        for a in range(kernel_size):\n","            for b in range(kernel_size):\n","                lowered_inputs[a*kernel_size+b] = inputs_padded[..., a:res+a, b:res+b].transpose(0, 1).reshape(i_chn, bs, -1)\n","                \n","        lowered_inputs = lowered_inputs.transpose(0, 1)\n","        lowered_inputs = lowered_inputs.reshape(i_chn*kernel_size*kernel_size, bs*res*res)        \n","        return lowered_inputs\n","    \n","    def outputs_lifting():\n","        outputs = lowered_outputs.reshape(o_chn, bs, res, res).transpose(0, 1)         \n","        return outputs\n","\n","    # Lower Weights\n","    weights_transformed = weight_lowering()\n","    \n","    # Lower Inputs\n","    inputs_transformed = inputs_lowering()   \n","\n","    # Compute Outputs    \n","    lowered_outputs = mmul_tiling(weights_transformed, inputs_transformed, tile_size, sim)\n","        \n","    # Lift Outputs\n","    outputs = outputs_lifting()     \n","    \n","    if bias is not None:\n","        outputs += bias.view(1, o_chn, 1, 1)\n","    \n","    return outputs"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1684886544043,"user":{"displayName":"Layfort","userId":"05574237463148173604"},"user_tz":-540},"id":"gkys_FOASWWC"},"outputs":[],"source":["class MMConv2d(nn.Conv2d):\n","    def __init__(self, in_channels, out_channels, kernel_size,sim=None, padding=1, stride=1, bias=False):\n","        super(MMConv2d, self).__init__(in_channels, out_channels, kernel_size, padding=padding, stride = stride)\n","        self.lowering = False\n","        self.tiling = False\n","        self.tile_size = -1\n","        self.sim = sim\n","        self.quant = torch.quantization.QuantStub()\n","        \n","    def forward(self, inputs):\n","        return conv2d(inputs, self.weight, padding=self.padding, tile_size=self.tile_size, bias=self.bias, sim= self.sim)\n","    \n","    def set_tilesize(self, tile_size=-1):\n","        self.tile_size = tile_size\n","        \n","    def simulation_test(self, inputs):\n","        \n","        # Compute Output\n","        q_weight = (self.weight.data*100).type(torch.int8)\n","        q_bias = (self.bias.data*100).type(torch.int8)\n","        print(\"Input size: \\t\", inputs.size())\n","        print(\"Weight size: \\t\", self.weight.size())\n","        pred_outputs = conv2d(inputs, q_weight, padding=self.padding, tile_size=self.tile_size, bias=q_bias,sim = self.sim)\n","        print(\"Output size: \\t\", pred_outputs.size())        \n","        print(\"=============================================\")\n","        \n","        # Evaluation\n","        true_outputs = F.conv2d(inputs, q_weight, padding=self.padding, bias=q_bias)\n","        correct = (pred_outputs - true_outputs).abs().max() < 1\n","        print(\"Correctness: \\t\", correct.item(), '\\n')      "]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"hYLjTb6QwFQj"},"source":["# 3) Test tiling and network"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1684886545892,"user":{"displayName":"Layfort","userId":"05574237463148173604"},"user_tz":-540},"id":"v6Kzmk9cTNk4"},"outputs":[],"source":["# Configurations\n","BS = 1\n","RES_X, RES_Y = (32, 32)\n","I_CHN = 4\n","O_CHN = 8\n","KERNEL_SIZE = 3\n","PADDING = 1\n","BIAS = False\n","\n","layer = MMConv2d(I_CHN, O_CHN, KERNEL_SIZE, padding = PADDING, bias=BIAS)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":302,"status":"ok","timestamp":1684886589293,"user":{"displayName":"Layfort","userId":"05574237463148173604"},"user_tz":-540},"id":"fuZmp_EETSLM","outputId":"f771397e-637b-41d2-bac8-53b163048c72"},"outputs":[{"name":"stdout","output_type":"stream","text":["Input size: \t torch.Size([1, 4, 32, 32])\n","Weight size: \t torch.Size([8, 4, 3, 3])\n","Output size: \t torch.Size([1, 8, 32, 32])\n","=============================================\n","Correctness: \t True \n","\n"]}],"source":["tile_size = 4\n","\n","layer.set_tilesize(tile_size)\n","\n","inputs = (torch.randn(BS, I_CHN, RES_Y, RES_X)*20).type(torch.int8)\n","layer.simulation_test(inputs)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"oyiuOBpmwNL9"},"source":["# 4) Bring Amaranth hardware designs"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":292,"status":"ok","timestamp":1684886595877,"user":{"displayName":"Layfort","userId":"05574237463148173604"},"user_tz":-540},"id":"Nw-NhGgIToZG"},"outputs":[],"source":["from amaranth import *\n","from enum import IntEnum\n","import math\n","from amaranth.lib.fifo import SyncFIFOBuffered"]},{"cell_type":"code","execution_count":46,"metadata":{"executionInfo":{"elapsed":682,"status":"ok","timestamp":1684887631303,"user":{"displayName":"Layfort","userId":"05574237463148173604"},"user_tz":-540},"id":"LiNHF6VdTq8I"},"outputs":[],"source":["# Amaranth hardware designs from previous Lab\n","\n","class MAC(Elaboratable):\n","    def __init__(self, num_bits, acc_bits, signed=True):\n","        self.num_bits = num_bits\n","        self.acc_bits = acc_bits\n","        self.signed = signed\n","\n","        self.in_a = Signal(Shape(num_bits, signed=signed))\n","        self.in_a_valid = Signal(1)\n","        self.in_b = Signal(Shape(num_bits, signed=signed))\n","        self.in_b_valid = Signal(1)\n","\n","        self.in_rst = Signal(1, reset_less=True)\n","\n","        self.out_d = Signal(Shape(acc_bits, signed=signed))\n","        self.out_d_valid = Signal(1)\n","        self.out_ovf = Signal(1)\n","\n","        self.tmp_prod = Signal(Shape(acc_bits, signed=signed))\n","        self.tmp_d = Signal(Shape(acc_bits, signed=signed))\n","        self.tmp_ovf = Signal(1)\n","\n","    def elaborate(self, platform):\n","        m = Module()\n","\n","        m.d.comb += [\n","            self.tmp_prod.eq(self.in_a * self.in_b),\n","            Cat(self.tmp_d, self.tmp_ovf).eq(\n","                self.out_d + self.tmp_prod),\n","        ]\n","\n","        # no need to write reset code\n","        with m.If(self.in_a_valid & self.in_b_valid):\n","            if self.signed:\n","                m.d.sync += [\n","                    self.out_ovf.eq(\n","                        self.out_ovf |\n","                        self.tmp_prod[-1] & self.out_d[-1] & ~self.tmp_d[-1] |\n","                        ~self.tmp_prod[-1] & ~self.out_d[-1] & self.tmp_d[-1])\n","                ]\n","            else:\n","                m.d.sync += [\n","                    self.out_ovf.eq(self.out_ovf | self.tmp_ovf),\n","                ]\n","            m.d.sync += [\n","                self.out_d.eq(self.tmp_d),\n","                self.out_d_valid.eq(1),\n","            ]\n","        return m\n","\n","\n","class PE(Elaboratable):\n","    def __init__(self, num_bits, acc_bits, cnt_bits, signed=True):\n","        self.num_bits = num_bits\n","        self.acc_bits = acc_bits\n","        self.cnt_bits = cnt_bits\n","        self.signed = signed\n","\n","        self.in_init = Signal(cnt_bits)\n","        self.in_rst = Signal(1, reset_less=True)\n","\n","        self.in_a = Signal(Shape(num_bits, signed=signed))\n","        self.in_b = Signal(Shape(num_bits, signed=signed))\n","\n","        self.out_d = Signal(Shape(acc_bits, signed=signed))\n","        self.out_d_valid = Signal(1)\n","        self.out_ovf = Signal(1)\n","\n","        self.cnt_target = Signal(cnt_bits)\n","        self.cnt = Signal(cnt_bits)\n","        self.cnt_ovf = Signal(1)\n","        self.cnt_next = Signal(cnt_bits + 1)\n","\n","        self.mac = MAC(num_bits=num_bits, acc_bits=acc_bits, signed=signed)\n","        self.is_exec = Signal(1)\n","\n","    def elaborate(self, platform):\n","        m = Module()\n","\n","        m.submodules.mac = mac = ResetInserter(self.mac.in_rst)(self.mac)\n","\n","        m.d.comb += [\n","            mac.in_a.eq(self.in_a),\n","            mac.in_a_valid.eq(self.is_exec),\n","            mac.in_b.eq(self.in_b),\n","            mac.in_b_valid.eq(self.is_exec),\n","            mac.in_rst.eq(~self.is_exec & self.in_init.any() | self.in_rst),\n","            self.out_d.eq(mac.out_d),\n","            self.out_d_valid.eq(mac.out_d_valid & ~self.is_exec),\n","            self.out_ovf.eq(mac.out_ovf),\n","            self.cnt_next.eq(self.cnt + 1),\n","        ]\n","\n","        with m.FSM(reset='INIT'):\n","            with m.State('INIT'):\n","                with m.If(self.in_init):\n","                    m.d.sync += [\n","                        self.cnt_target.eq(self.in_init),\n","                        self.cnt.eq(0),\n","                        self.cnt_ovf.eq(0),\n","                        self.is_exec.eq(1),\n","                    ]\n","                    m.next = 'EXEC'\n","            with m.State('EXEC'):\n","                m.d.sync += [\n","                    Cat(self.cnt, self.cnt_ovf).eq(self.cnt_next)\n","                ]\n","                with m.If(self.cnt_next[:-1] == self.cnt_target):\n","                    m.next = 'INIT'\n","                    m.d.sync += [\n","                        self.is_exec.eq(0),\n","                    ]\n","\n","        return m\n","\n","        \n","class AdderTree(Elaboratable):\n","    def __init__(self, acc_bits, fan_in, signed=True):\n","        self.acc_bits = acc_bits\n","        self.fan_in = fan_in\n","        self.signed = signed\n","        assert is_power_of_two(fan_in)\n","        assert fan_in >= 2\n","\n","        self.in_data = Array([\n","            Signal(Shape(acc_bits, signed=signed), name=f'in_data_{fan_in}_{i}')\n","            for i in range(fan_in)])\n","        self.in_ovf = Array([Signal(1, name=f'in_ovf_{fan_in}_{i}')\n","                             for i in range(fan_in)])\n","        self.in_valid = Array([Signal(1, name=f'in_valid_{fan_in}_{i}')\n","                               for i in range(fan_in)])\n","        self.out_d = Signal(Shape(acc_bits, signed=signed))\n","        self.out_ovf = Signal(1)\n","        self.out_valid = Signal(1)\n","\n","        self.tmp_ovf = Signal(1)\n","\n","        self.tree_l = None\n","        self.tree_r = None\n","        if fan_in > 2:\n","            self.tree_l = AdderTree(acc_bits, fan_in // 2, signed=signed)\n","            self.tree_r = AdderTree(acc_bits, fan_in // 2, signed=signed)\n","\n","    def elaborate(self, platform):\n","        m = Module()\n","\n","        if self.fan_in > 2:\n","            m.submodules.tree_l = tree_l = self.tree_l\n","            m.submodules.tree_r = tree_r = self.tree_r\n","\n","            for i in range(self.fan_in):\n","                half = self.fan_in // 2\n","                if i < half:\n","                    m.d.comb += [\n","                        tree_l.in_data[i].eq(self.in_data[i]),\n","                        tree_l.in_ovf[i].eq(self.in_ovf[i]),\n","                        tree_l.in_valid[i].eq(self.in_valid[i]),\n","                    ]\n","                else:\n","                    m.d.comb += [\n","                        tree_r.in_data[i - half].eq(self.in_data[i]),\n","                        tree_r.in_ovf[i - half].eq(self.in_ovf[i]),\n","                        tree_r.in_valid[i - half].eq(self.in_valid[i]),\n","                    ]\n","            m.d.comb += [\n","                Cat(self.out_d, self.tmp_ovf).eq(\n","                    tree_l.out_d + tree_r.out_d),\n","                self.out_valid.eq(tree_l.out_valid & tree_r.out_valid),\n","            ]\n","            if self.signed:\n","                m.d.comb += [\n","                    self.out_ovf.eq(\n","                        tree_l.out_ovf | tree_r.out_ovf |\n","                        (~self.tree_l.out_d[-1] & ~self.tree_r.out_d[-1] & self.out_d[-1]) |\n","                        (self.tree_l.out_d[-1] & self.tree_r.out_d[-1] & ~self.out_d[-1])\n","                    )\n","                ]\n","            else:\n","                m.d.comb += [\n","                    self.out_ovf.eq(\n","                        self.tmp_ovf | tree_l.out_ovf | tree_r.out_ovf),\n","                ]\n","        else:\n","            m.d.comb += [\n","                Cat(self.out_d, self.tmp_ovf).eq(\n","                    self.in_data[0] + self.in_data[1]),\n","                self.out_valid.eq(self.in_valid[0] & self.in_valid[1])\n","            ]\n","            if self.signed:\n","                m.d.comb += [\n","                    self.out_ovf.eq(\n","                        self.in_ovf[0] | self.in_ovf[1] |\n","                        (~self.in_data[0][-1] & ~self.in_data[1][-1] & self.out_d[-1]) |\n","                        (self.in_data[0][-1] & self.in_data[1][-1] & ~self.out_d[-1])\n","                    )\n","                ]\n","            else:\n","                m.d.comb += [\n","                    self.out_ovf.eq(\n","                        self.tmp_ovf | self.in_ovf[0] | self.in_ovf[1]),\n","                ]\n","\n","        return m\n","\n","def is_power_of_two(x):\n","    return (x & (x - 1)) == 0\n","\n","\n","class ACTCODE(IntEnum):\n","    NONE = 0\n","    RELU = 1\n","\n","\n","class PEStack(Elaboratable):\n","    def __init__(self, num_bits, width, cnt_bits, signed=True):\n","        self.width = width  # input bitwidth\n","        self.acc_bits = num_bits\n","        self.num_stack = width // num_bits\n","        self.num_bits = num_bits\n","        self.cnt_bits = cnt_bits\n","        self.signed = signed\n","\n","        assert width in [32, 64, 128]\n","        assert width % num_bits == 0\n","        assert is_power_of_two(self.num_stack)\n","\n","        self.adder_tree = AdderTree(\n","            acc_bits=self.acc_bits, fan_in=self.num_stack, signed=signed)\n","\n","        self.pe_arr = [\n","            PE(num_bits=num_bits, acc_bits=self.acc_bits,\n","               cnt_bits=cnt_bits, signed=signed)\n","            for _ in range(self.num_stack)]\n","\n","        self.in_rst = Signal(1, reset_less=True)\n","        self.in_init = Signal(cnt_bits)\n","        self.in_a = Signal(width)\n","        self.in_b = Signal(width)\n","        self.in_act = Signal(1)\n","\n","        self.out_d = Signal(Shape(self.acc_bits, signed=True))\n","        self.out_ready = Signal(1)\n","        self.out_ovf = Signal(1)\n","\n","    def elaborate(self, platform):\n","        m = Module()\n","\n","        m.submodules.adder_tree = adder_tree = self.adder_tree\n","\n","        with m.If(self.signed & (self.in_act == ACTCODE.RELU)):\n","            m.d.comb += [\n","                self.out_d.eq(Mux(adder_tree.out_d >= 0, adder_tree.out_d, 0)),\n","            ]\n","        with m.Else():  # NONE\n","            m.d.comb += [\n","                self.out_d.eq(adder_tree.out_d),\n","            ]\n","\n","        m.d.comb += [\n","            self.out_d.eq(adder_tree.out_d),\n","            self.out_ready.eq(adder_tree.out_valid),\n","            self.out_ovf.eq(adder_tree.out_ovf),\n","        ]\n","\n","        for i, pe in enumerate(self.pe_arr):\n","            m.submodules += pe\n","\n","            m.d.comb += [\n","                pe.in_a.eq(\n","                    self.in_a[i*self.num_bits: (i+1)*self.num_bits]),\n","                pe.in_b.eq(\n","                    self.in_b[i*self.num_bits: (i+1)*self.num_bits]),\n","                pe.in_init.eq(self.in_init),\n","                pe.in_rst.eq(self.in_rst),\n","                adder_tree.in_data[i].eq(pe.out_d),\n","                adder_tree.in_valid[i].eq(pe.out_d_valid),\n","                adder_tree.in_ovf[i].eq(pe.out_ovf),\n","            ]\n","        return m"]},{"cell_type":"code","execution_count":47,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1684887632040,"user":{"displayName":"Layfort","userId":"05574237463148173604"},"user_tz":-540},"id":"8Mn_Wa7sSQJD"},"outputs":[],"source":["def mmul_tiling(matA, matB, t, simulator):\n","    a, c = matA.size()\n","    _, b = matB.size()\n","    matC = torch.zeros(a, b).type(torch.int8)\n","    \n","    if simulator is not None:\n","      for j in range((b + t - 1)//t):\n","        for i in range((a + t - 1)//t):\n","          #######  TODO  #######\n","          # Hint: use simulator.set_input\n","          \n","          simulator.set_input(matA[i*t:(i+1)*t, :].reshape(-1), matB[:, j*t:(j+1)*t].reshape(-1))\n","\n","          #######################\n","          simulator.sim.add_sync_process(simulator.bench)\n","          simulator.sim.run()\n","          tileC = matC[i*t:(i+1)*t, j*t:(j+1)*t]\n","          tileC += simulator.output\n","\n","    else:\n","      for i in range((a + t - 1)//t):\n","          for j in range((b + t - 1)//t):\n","            tileC = matC[i*t:(i+1)*t, j*t:(j+1)*t]\n","            for k in range((c + t - 1)//t):\n","              tileA = matA[i*t:(i+1)*t, k*t:(k+1)*t]\n","              tileB = matB[k*t:(k+1)*t, j*t:(j+1)*t]\n","              tileC += tmul(tileA, tileB, t)\n","    \n","    return matC"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"CIO6JbmLwWbH"},"source":["# 5) Make simulator class for communication"]},{"cell_type":"code","execution_count":48,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1684887632041,"user":{"displayName":"Layfort","userId":"05574237463148173604"},"user_tz":-540},"id":"RBeBqAmBTzc2"},"outputs":[],"source":["from amaranth.sim import Simulator\n","import numpy as np\n","from collections import deque\n","from pathlib import Path"]},{"cell_type":"code","execution_count":49,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1684887632041,"user":{"displayName":"Layfort","userId":"05574237463148173604"},"user_tz":-540},"id":"6-18mpEiUEZc"},"outputs":[],"source":["class ComunicationSimulator():\n","  def __init__(self, width=32, num_bits = 8):\n","      self.output = 0\n","\n","      self.width = width\n","      self.num_bits = num_bits\n","      signed = True\n","      cnt_bits = 5\n","\n","      self.dut = PEStack(self.num_bits, self.width,\n","                      cnt_bits=cnt_bits, signed=signed)\n","      self.dut = ResetInserter(self.dut.in_rst)(self.dut)\n","\n","      # make amaranth simulator as attribute of our simulator\n","      self.sim = Simulator(self.dut)\n","      self.sim.add_clock(1e-6)\n","\n","      self.i_stack = []\n","      self.j_stack = []\n","      self.count = 0\n","      \n","\n","\n","  def set_input(self, input_a, input_b):\n","      self.i_stack = []\n","      self.j_stack = []\n","      self.count = len(input_a)//4\n","\n","      #input_a and input_b are lists of tile size tensor\n","      for i in range(self.count):\n","          tmp = 0\n","          for l in range(self.width // self.num_bits):\n","            if int(input_a[i*4 + l].item())>=0:\n","              tmp = (tmp << self.num_bits) +\\\n","                    int(input_a[i*4 + l].item())\n","            else:\n","              tmp = (tmp << self.num_bits) +\\\n","                    int(2**self.num_bits +input_a[i*4 + l].item())\n","          self.i_stack.append(tmp)\n","\n","          tmp = 0\n","          for l in range(self.width // self.num_bits):\n","            if int(input_b[i*4 + l].item())>=0:\n","              tmp = (tmp << self.num_bits) +\\\n","                    int(input_b[i*4 + l].item())\n","            else:\n","              tmp = (tmp << self.num_bits) +\\\n","                    int(2**self.num_bits +input_b[i*4 + l].item())\n","          self.j_stack.append(tmp)\n","\n","  # run single clock cycle\n","  def test_case(self, dut, in_a, in_b, in_init):\n","      yield dut.in_a.eq(in_a)\n","      yield dut.in_b.eq(in_b)\n","      yield dut.in_init.eq(in_init)\n","      yield\n","      out_data = yield dut.out_d\n","      return out_data\n","\n","\n","  def bench(self):\n","        # initialize\n","        yield from self.test_case(self.dut, 0, 0, self.count)\n","        # feed\n","        for i in range(self.count):\n","            yield from self.test_case(self.dut, self.i_stack[i], self.j_stack[i],0)\n","        # get output\n","        self.output = yield from self.test_case(self.dut, 0, 0, 0)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"qwh9486GwiGP"},"source":["# 6) Test Pytorch to Amaranth communication"]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":475246,"status":"ok","timestamp":1684888107282,"user":{"displayName":"Layfort","userId":"05574237463148173604"},"user_tz":-540},"id":"mXBHoFsRULPo","outputId":"30c2fe69-43dd-497f-917f-877beb8223fe"},"outputs":[{"name":"stdout","output_type":"stream","text":["Input size: \t torch.Size([1, 4, 32, 32])\n","Weight size: \t torch.Size([8, 4, 3, 3])\n","Output size: \t torch.Size([1, 8, 32, 32])\n","=============================================\n","Correctness: \t True \n","\n"]}],"source":["np.random.seed(42)\n","simul = ComunicationSimulator()\n","# initialize layer with simulator\n","layer = MMConv2d(I_CHN, O_CHN, KERNEL_SIZE, sim = simul, padding=PADDING, bias=BIAS)\n","\n","# fixed to 1 in this practice\n","tile_size = 1\n","\n","layer.set_tilesize(tile_size)\n","\n","inputs = (torch.randn(BS, I_CHN, RES_Y, RES_X)*20).type(torch.int8)\n","layer.simulation_test(inputs)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
