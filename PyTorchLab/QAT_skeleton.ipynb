{"cells":[{"cell_type":"code","execution_count":1,"id":"c299dc43","metadata":{"executionInfo":{"elapsed":5922,"status":"ok","timestamp":1683676520377,"user":{"displayName":"Layfort","userId":"05574237463148173604"},"user_tz":-540},"id":"c299dc43"},"outputs":[],"source":["import torch\n","import torchvision.datasets as dsets\n","import torchvision.transforms as transforms\n","import torch.nn.init\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import os"]},{"attachments":{},"cell_type":"markdown","id":"151a875b","metadata":{"id":"151a875b"},"source":["### hyper parameter"]},{"cell_type":"code","execution_count":2,"id":"324e1655","metadata":{"executionInfo":{"elapsed":1276,"status":"ok","timestamp":1683679391028,"user":{"displayName":"Layfort","userId":"05574237463148173604"},"user_tz":-540},"id":"324e1655"},"outputs":[{"name":"stdout","output_type":"stream","text":["True\n"]}],"source":["print(torch.cuda.is_available())\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# 랜덤 시드 고정\n","torch.manual_seed(777)\n","\n","# GPU 사용 가능일 경우 랜덤 시드 고정\n","if device == \"cuda\":\n","    torch.cuda.manual_seed_all(777)\n","\n","# 하이퍼 파라미터\n","learning_rate = 0.001\n","training_epochs = 40\n","batch_size = 128\n","quant_epoch = 20"]},{"attachments":{},"cell_type":"markdown","id":"41b37e3d","metadata":{"id":"41b37e3d"},"source":["### dataset and data loader"]},{"cell_type":"code","execution_count":3,"id":"eeb5a67c","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1683679391029,"user":{"displayName":"Layfort","userId":"05574237463148173604"},"user_tz":-540},"id":"eeb5a67c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST\\raw\\train-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 14085640.33it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./MNIST\\raw\\train-images-idx3-ubyte.gz to ./MNIST\\raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST\\raw\\train-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 28881/28881 [00:00<00:00, 29028443.28it/s]"]},{"name":"stdout","output_type":"stream","text":["Extracting ./MNIST\\raw\\train-labels-idx1-ubyte.gz to ./MNIST\\raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 9801989.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./MNIST\\raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4542/4542 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Extracting ./MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./MNIST\\raw\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["mnist_train = dsets.MNIST(\n","    root=\"./\",  # 다운로드 경로 지정\n","    train=True,  # True를 지정하면 훈련 데이터로 다운로드\n","    transform=transforms.ToTensor(),  # 텐서로 변환\n","    download=True,\n",")\n","\n","mnist_test = dsets.MNIST(\n","    root=\"./\",  # 다운로드 경로 지정\n","    train=False,  # False를 지정하면 테스트 데이터로 다운로드\n","    transform=transforms.ToTensor(),  # 텐서로 변환\n","    download=True,\n",")\n","\n","\n","data_loader = torch.utils.data.DataLoader(\n","    dataset=mnist_train, batch_size=batch_size, shuffle=True, drop_last=True\n",")"]},{"attachments":{},"cell_type":"markdown","id":"e_IArBUcii2q","metadata":{"id":"e_IArBUcii2q"},"source":["### STE"]},{"cell_type":"code","execution_count":10,"id":"-6Q3eP9OiiK6","metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1683679392076,"user":{"displayName":"Layfort","userId":"05574237463148173604"},"user_tz":-540},"id":"-6Q3eP9OiiK6"},"outputs":[],"source":["class roundpass(torch.autograd.Function):\n","    @staticmethod\n","    def forward(ctx, input):\n","        ## TODO ##\n","        ## Define output w.r.t. input\n","        ctx.save_for_backward(input)\n","        output = torch.round(input=input)\n","        return output\n","\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        ## TODO ##\n","        ## Define grad_input w.r.t. grad_output\n","        return grad_output\n","\n","\n","roundpass = roundpass.apply"]},{"attachments":{},"cell_type":"markdown","id":"iLqpRmHzjxRZ","metadata":{"id":"iLqpRmHzjxRZ"},"source":["### Quantization module"]},{"cell_type":"code","execution_count":11,"id":"A63Py1krzL1C","metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1683679392076,"user":{"displayName":"Layfort","userId":"05574237463148173604"},"user_tz":-540},"id":"A63Py1krzL1C"},"outputs":[],"source":["class Quantizer(nn.Module):\n","    def __init__(self, bits=8, always_pos=False):\n","        super(Quantizer, self).__init__()\n","        \n","        self.first = True\n","        self.num_steps = 2 ** bits\n","        self.always_pos = always_pos\n","     \n","        self.Qp = 2**(bits-1) - 1\n","        self.Qn = - 2**(bits-1) \n","\n","    def forward(self, x):\n","        if self.first:\n","          self.alpha = x.abs().max().detach()\n","          self.first = False\n","\n","        step_size = 2 * self.alpha / self.num_steps   \n","        if self.always_pos:\n","            off = self.alpha\n","        else:\n","            off = 0 \n","\n","        # Quantization\n","        q_x = torch.clamp(roundpass((x - off)/step_size), self.Qn, self.Qp) * step_size + off\n","        return q_x"]},{"attachments":{},"cell_type":"markdown","id":"X1f61Rgre3_d","metadata":{"id":"X1f61Rgre3_d"},"source":["### Quantization aware modules"]},{"cell_type":"code","execution_count":12,"id":"LSlkN56drpKa","metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1683679392077,"user":{"displayName":"Layfort","userId":"05574237463148173604"},"user_tz":-540},"id":"LSlkN56drpKa"},"outputs":[],"source":["class CustomConv2d(nn.Conv2d):\n","    def __init__(self, *args, **kwargs):\n","        super(CustomConv2d, self).__init__(*args, **kwargs)\n","        self.q_w = Quantizer()\n","        self.q_a = Quantizer(always_pos=True)\n","        self.is_quant = False # No quantization by default\n","\n","    def forward(self, x):\n","      if self.is_quant:        \n","          ## TODO ## \n","          ## quantize the weights and inputs using the ``Quantize`` modules. \n","          inputs = self.q_a.forward(x)\n","          weight = self.q_w.forward(self.weight)\n","      else:\n","          inputs = x\n","          weight = self.weight\n","\n","      return F.conv2d(\n","          inputs,\n","          weight,\n","          bias=self.bias,\n","          stride=self.stride,\n","          padding=self.padding,\n","          dilation=self.dilation,\n","          groups=self.groups,\n","      )\n","\n","\n","class CustomLinear(nn.Linear):\n","    def __init__(self, *args, **kwargs):\n","        super(CustomLinear, self).__init__(*args, **kwargs)\n","        self.q_w = Quantizer()\n","        self.q_a = Quantizer(always_pos=True)\n","        self.is_quant = False # No quantization by default\n","\n","    def forward(self, x):\n","      if self.is_quant:        \n","          ## TODO ## \n","          ## quantize the weights and inputs using the ``Quantize`` modules. \n","          weight = self.q_w.forward(self.weight)\n","          inputs = self.q_a.forward(x)\n","      else:\n","          weight = self.weight\n","          inputs = x\n","\n","      return F.linear(inputs, weight, bias=self.bias)"]},{"attachments":{},"cell_type":"markdown","id":"26a8a980","metadata":{"id":"26a8a980"},"source":["### neural network "]},{"cell_type":"code","execution_count":13,"id":"b9974d56","metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1683679392077,"user":{"displayName":"Layfort","userId":"05574237463148173604"},"user_tz":-540},"id":"b9974d56"},"outputs":[],"source":["class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","\n","        self.conv = CustomConv2d(1, 6, kernel_size=3, stride=1, padding=0, bias=False)\n","        self.layer1 = nn.Sequential(\n","            self.conv,\n","            nn.BatchNorm2d(6),\n","            nn.ReLU(),\n","        )\n","\n","        self.fc1 = CustomLinear(4056, 30, bias=False)\n","        self.fc2 = CustomLinear(30, 10, bias=False)\n","        self.layer2 = nn.Sequential(self.fc1, torch.nn.ReLU(), self.fc2)\n","\n","    def forward(self, x):\n","        out = self.layer1(x)\n","        out = out.view(out.size(0), -1)\n","        out = self.layer2(out)\n","        return out"]},{"attachments":{},"cell_type":"markdown","id":"def6043a","metadata":{"id":"def6043a"},"source":["### custom function for evaluation"]},{"cell_type":"code","execution_count":14,"id":"bdab3971","metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1683679392077,"user":{"displayName":"Layfort","userId":"05574237463148173604"},"user_tz":-540},"id":"bdab3971"},"outputs":[],"source":["if not os.path.exists(\"weight\"):\n","  os.mkdir('./weight')\n","\n","def eval_custom(model_, num_imgs):\n","    with torch.no_grad():\n","        X_test = (\n","            mnist_test.data.view(len(mnist_test), 1, 28, 28).float().to(device)\n","        )\n","        Y_test = mnist_test.targets.to(device)\n","        prediction = model_(X_test)\n","        correct_prediction = torch.argmax(prediction, 1) == Y_test\n","        correct_prediction_100 = (\n","            torch.argmax(prediction[:num_imgs], 1) == Y_test[:num_imgs]\n","        )\n","        accuracy = correct_prediction.float().mean()\n","        accuracy_100 = correct_prediction_100.float().mean()\n","        print(\"Accuracy_all:\", accuracy.item())\n","        print(f\"Accuracy_{num_imgs}:\", accuracy_100.item())\n","\n","        torch.save(\n","            model.state_dict(),\n","            f\"./weight/model_{str(accuracy.item()):.7}_{str(accuracy_100.item()):.7}.pth\",\n","        )"]},{"attachments":{},"cell_type":"markdown","id":"5c60fead","metadata":{"id":"5c60fead"},"source":["### iteration loop"]},{"cell_type":"code","execution_count":9,"id":"M5xy9jVcBQCA","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":413862,"status":"ok","timestamp":1683679806304,"user":{"displayName":"Layfort","userId":"05574237463148173604"},"user_tz":-540},"id":"M5xy9jVcBQCA","outputId":"82f033b9-5816-4f80-e606-abd998e3537d"},"outputs":[{"name":"stdout","output_type":"stream","text":["총 배치의 수 : 468\n","Accuracy_all: 0.8931999802589417\n","Accuracy_100: 0.8899999856948853\n","[Epoch:    1] cost = 0.530423105\n","Accuracy_all: 0.9013999700546265\n","Accuracy_100: 0.8899999856948853\n","[Epoch:    2] cost = 0.432589114\n","Accuracy_all: 0.9099999666213989\n","Accuracy_100: 0.9099999666213989\n","[Epoch:    3] cost = 0.389850855\n","Accuracy_all: 0.9146999716758728\n","Accuracy_100: 0.9399999976158142\n","[Epoch:    4] cost = 0.358769238\n","Accuracy_all: 0.9185000061988831\n","Accuracy_100: 0.9300000071525574\n","[Epoch:    5] cost = 0.335046828\n","Accuracy_all: 0.9236999750137329\n","Accuracy_100: 0.9300000071525574\n","[Epoch:    6] cost = 0.31562832\n","Accuracy_all: 0.9258999824523926\n","Accuracy_100: 0.949999988079071\n","[Epoch:    7] cost = 0.299797207\n","Accuracy_all: 0.9282999634742737\n","Accuracy_100: 0.949999988079071\n","[Epoch:    8] cost = 0.285898089\n","Accuracy_all: 0.9299999475479126\n","Accuracy_100: 0.949999988079071\n","[Epoch:    9] cost = 0.273763508\n","Accuracy_all: 0.9315999746322632\n","Accuracy_100: 0.949999988079071\n","[Epoch:   10] cost = 0.26320383\n","Accuracy_all: 0.9335999488830566\n","Accuracy_100: 0.949999988079071\n","[Epoch:   11] cost = 0.253535837\n","Accuracy_all: 0.9361000061035156\n","Accuracy_100: 0.949999988079071\n","[Epoch:   12] cost = 0.244721711\n","Accuracy_all: 0.9375\n","Accuracy_100: 0.949999988079071\n","[Epoch:   13] cost = 0.236710727\n","Accuracy_all: 0.9386000037193298\n","Accuracy_100: 0.949999988079071\n","[Epoch:   14] cost = 0.229082644\n","Accuracy_all: 0.9405999779701233\n","Accuracy_100: 0.949999988079071\n","[Epoch:   15] cost = 0.222502604\n","Accuracy_all: 0.9418999552726746\n","Accuracy_100: 0.949999988079071\n","[Epoch:   16] cost = 0.215831414\n","Accuracy_all: 0.9430999755859375\n","Accuracy_100: 0.949999988079071\n","[Epoch:   17] cost = 0.210065857\n","Accuracy_all: 0.9444999694824219\n","Accuracy_100: 0.9599999785423279\n","[Epoch:   18] cost = 0.204358518\n","Accuracy_all: 0.9460999965667725\n","Accuracy_100: 0.9699999690055847\n","[Epoch:   19] cost = 0.198946804\n","Accuracy_all: 0.9472000002861023\n","Accuracy_100: 0.9599999785423279\n","[Epoch:   20] cost = 0.194021091\n","Accuracy_all: 0.9351999759674072\n","Accuracy_100: 0.9399999976158142\n","[Epoch:   21] cost = 0.189303309\n","Accuracy_all: 0.9351999759674072\n","Accuracy_100: 0.9399999976158142\n","[Epoch:   22] cost = 0.184771568\n","Accuracy_all: 0.9368000030517578\n","Accuracy_100: 0.9399999976158142\n","[Epoch:   23] cost = 0.180643842\n","Accuracy_all: 0.9361000061035156\n","Accuracy_100: 0.949999988079071\n","[Epoch:   24] cost = 0.176447749\n","Accuracy_all: 0.9389999508857727\n","Accuracy_100: 0.949999988079071\n","[Epoch:   25] cost = 0.172525018\n","Accuracy_all: 0.9390999674797058\n","Accuracy_100: 0.9399999976158142\n","[Epoch:   26] cost = 0.16886805\n","Accuracy_all: 0.9395999908447266\n","Accuracy_100: 0.9399999976158142\n","[Epoch:   27] cost = 0.165329427\n","Accuracy_all: 0.9407999515533447\n","Accuracy_100: 0.949999988079071\n","[Epoch:   28] cost = 0.161828548\n","Accuracy_all: 0.9430999755859375\n","Accuracy_100: 0.949999988079071\n","[Epoch:   29] cost = 0.158120513\n","Accuracy_all: 0.944599986076355\n","Accuracy_100: 0.949999988079071\n","[Epoch:   30] cost = 0.155189529\n","Accuracy_all: 0.9438999891281128\n","Accuracy_100: 0.949999988079071\n","[Epoch:   31] cost = 0.152187675\n","Accuracy_all: 0.9451999664306641\n","Accuracy_100: 0.949999988079071\n","[Epoch:   32] cost = 0.149417475\n","Accuracy_all: 0.9447999596595764\n","Accuracy_100: 0.949999988079071\n","[Epoch:   33] cost = 0.146449596\n","Accuracy_all: 0.946899950504303\n","Accuracy_100: 0.949999988079071\n","[Epoch:   34] cost = 0.143914968\n","Accuracy_all: 0.9480999708175659\n","Accuracy_100: 0.949999988079071\n","[Epoch:   35] cost = 0.141043678\n","Accuracy_all: 0.946899950504303\n","Accuracy_100: 0.949999988079071\n","[Epoch:   36] cost = 0.138690978\n","Accuracy_all: 0.9483999609947205\n","Accuracy_100: 0.949999988079071\n","[Epoch:   37] cost = 0.136012137\n","Accuracy_all: 0.9490000009536743\n","Accuracy_100: 0.9599999785423279\n","[Epoch:   38] cost = 0.133944929\n","Accuracy_all: 0.9506999850273132\n","Accuracy_100: 0.9599999785423279\n","[Epoch:   39] cost = 0.131664619\n","Accuracy_all: 0.9498999714851379\n","Accuracy_100: 0.949999988079071\n","[Epoch:   40] cost = 0.129399717\n"]}],"source":["model = CNN().to(device)\n","\n","criterion = torch.nn.CrossEntropyLoss().to(device)  # 비용 함수에 소프트맥스 함수 포함되어져 있음.\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","scheduler = torch.optim.lr_scheduler.LinearLR(\n","    optimizer, start_factor=1.0, end_factor=1e-2, total_iters=training_epochs\n",")\n","\n","total_batch = len(data_loader)\n","print(\"총 배치의 수 : {}\".format(total_batch))\n","\n","for epoch in range(training_epochs):\n","    avg_cost = 0\n","\n","    if epoch >= quant_epoch:\n","        for m in model.modules():\n","            if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n","                m.is_quant=True\n","\n","    for X, Y in data_loader:  # 미니 배치 단위로 꺼내온다. X는 미니 배치, Y는 레이블.\n","        # image is already size of (28x28), no reshape\n","        # label is not one-hot encoded\n","        X = X.to(device)\n","        Y = Y.to(device)\n","\n","        optimizer.zero_grad()\n","        hypothesis = model(X)\n","        cost = criterion(hypothesis, Y)\n","        cost.backward()\n","        optimizer.step()\n","        scheduler.step()\n","\n","        avg_cost += cost / total_batch\n","    eval_custom(model, 100)\n","\n","    print(\"[Epoch: {:>4}] cost = {:>.9}\".format(epoch + 1, avg_cost))"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":5}
